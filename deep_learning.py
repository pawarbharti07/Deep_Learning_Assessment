# -*- coding: utf-8 -*-
"""Deep Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EMVMjN620w9mkT2uOHcLsS4ffLKWPJtG
"""

#Load dataset
import pandas as pd

data = pd.read_csv("/content/Scene_Classification_updated.csv")
print(data.head())
print(data['CLASS2'].value_counts())

from PIL import Image
import matplotlib.pyplot as plt
import requests
from io import BytesIO

url = "https://raw.githubusercontent.com/jordan-bird/Scene-Classification-Images-and-Audio/master/images/forest/forest0.png"

response = requests.get(url)
img = Image.open(BytesIO(response.content))

plt.imshow(img)
plt.axis("off")

import os
test_path = data['IMAGE'].iloc[0]
print("Path:", test_path)
print("Exists:",os.path.exists(test_path))

#2. Preprocess Images (Resize & Normalize).
import requests
import cv2
import numpy as np
from io import BytesIO
from PIL import Image

IMG_SIZE = 128

def load_image_from_url(url):
    try:
        response = requests.get(url, timeout=5)
        img = Image.open(BytesIO(response.content)).convert("RGB")
        img = img.resize((IMG_SIZE, IMG_SIZE))
        img = np.array(img) / 255.0
        return img
    except Exception as e:
        print("‚ùå Failed to load:",url)
        return None

X_images = []
valid_labels = []

for url, label in zip(data['IMAGE'], data['CLASS2']):
    img = load_image_from_url(url)
    if img is not None:
        X_images.append(img)
        valid_labels.append(label)

X_images = np.array(X_images)

import matplotlib.pyplot as plt

plt.imshow(X_images[0])
plt.axis("off")
plt.show()

import os

os.makedirs("downloaded_images", exist_ok=True)

def download_image(url, filename):
    img = load_image_from_url(url)
    if img is not None:
        cv2.imwrite(f"downloaded_images/{filename}.jpg", (img*255).astype(np.uint8))

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
y = le.fit_transform(valid_labels)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_images, y, test_size=0.2, random_state=42)

#4. Build CNN for Image Classification
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

cnn_model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(le.classes_), activation='softmax')
])

cnn_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

cnn_model.summary()

#5. Train and evaluate model using accuracy & confusion matrix.
cnn_model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=10,
    batch_size=32
)

from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns

y_pred_cnn = np.argmax(cnn_model.predict(X_test), axis=1)

print("CNN Accuracy:", accuracy_score(y_test, y_pred_cnn))

cm = confusion_matrix(y_test, y_pred_cnn)
sns.heatmap(cm, annot=True, fmt='d')
plt.title("CNN Confusion Matrix")
plt.show()

#8. Use data augmentation for better generalization.
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
)

datagen.flow(X_train, y_train, batch_size=32)

#9. Visualize predictions (correct vs wrong).
correct = np.where(y_pred_cnn == y_test)[0]
wrong = np.where(y_pred_cnn != y_test)[0]

plt.figure(figsize=(10,4))
for i, idx in enumerate(wrong[:5]):
    plt.subplot(1,5,i+1)
    plt.imshow(X_test[idx])
    plt.title(f"T:{le.inverse_transform([y_test[idx]])[0]}\nP:{le.inverse_transform([y_pred_cnn[idx]])[0]}")
    plt.axis('off')
plt.show()

